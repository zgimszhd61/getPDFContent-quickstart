软件漏洞检测对于维护系统安全和个人隐私至关重要。随着网络环境变得日益复杂和攻击技术快速发展，软件系统面临着各种威胁，长期以来困扰着软件组织。特别是，漏洞是可能导致信息泄漏、数据篡改和系统破坏等关键威胁之一。漏洞检测的目的是识别漏洞，减轻其影响，并预防恶意攻击。此外，漏洞检测有助于提高软件质量、可用性和可信度。如今，在现代软件开发中，漏洞检测已成为必备的环节。

许多自动静态分析工具（ASATs）已经被应用于漏洞检测。然而，一方面，ASAT的输出很难验证，因为需要开发者掌握更多的专业知识和漏洞检测经验。另一方面，ASAT的性能较差（例如高误报率），因为它们是基于字符串模式匹配的。

近年来，深度学习在自然语言处理领域的发展激发了研究人员将深度学习模型整合到自动漏洞分析工具（ASATs）中。这些现代ASATs通常在漏洞检测方面表现优于传统工具。然而，在实验数据集方面表现良好的深度学习模型可能在实际项目中遭遇严重性能下降。这主要是因为源代码结构的复杂性和漏洞特征的隐藏。使用深度学习模型的ASATs来检测漏洞对一系列下游任务产生影响，包括但不限于漏洞验证、本地化和修复。此外，对于负责检查深度学习模型指示的漏洞的开发人员来说也具有挑战性。

近年来，像ChatGPT和Copilot这样的大型语言模型(LLMs)在各种任务中展现出卓越的性能。然而，在漏洞检测方面，LLMs尚未取得令人满意的结果。戴等人指出，主要原因之一是LLMs的不恰当使用。LLMs是通过大量数据进行预训练的，但并非所有的数据都能对漏洞检测等下游任务产生积极的影响。为解决这一问题有两种技术：微调和提示工程。微调是一种常用的技术，但需要大量的计算资源和时间。带提示的LLMs允许用户与LLMs进行交互，以产生定制化结果。然而，由于检测性能极易受提示影响，通用提示框架无法实现令人满意的性能表现。

引导工程让LLMs能够适应特定的下游任务并生成定制化的输出。此外，引导工程还可以与微调技术共同使用，使其成为一种成本有效且有前途的漏洞检测技术。

杨等人：提交给爱思唯尔的预印本 第1页（共15页）arXiv:2405.01202v1 [cs.SE] 2024年5月2日深度学习增强的大型语言模型提示框架 之前的工作已经利用LLMs进行漏洞检测，采用了各种提示框架[45,11,34,30]。

然而，现有的提示信息为LLMs提供了有限的信息，使它们在真实项目中提供的帮助有限。为了解决这个问题，我们提出了一个定制的提示框架 DLAP2。尽管 DL 模型在多个项目中无法达到令人满意的性能，但它们在单个项目中具有卓越的表现。DLAP 的核心思想是使用预训练的 DL 模型来激发对LLMs的自适应隐式微调，以适应目标项目。我们在三个类别中选择最合适的 DL 模型作为插件，以增强 DLAP。这一过程通过两种最先进的提示实现：上下文学习（ICL）提示和思维链（COT）提示。一方面，ICL 提示利用局部敏感哈希（LSH）来采样与输入代码类似的候选代码片段。然后，使用预训练的 DL 模型来获取候选片段的预测概率。候选代码片段及其对应的概率的组合形成了输入代码的 ICL 提示。另一方面，COT 提示综合了静态扫描工具和预训练的 DL 模型的结果作为查询。

在进行这些查询之后，DLAP会在我们根据通用弱点枚举（CWE3）构建的检测步骤模板库中找到相应的COT模板。然后，DLAP使用这些COT模板为输入代码生成定制的完成检测COT提示。这可以促使LLMs进行内在微调，以实现更好的漏洞检测性能，并提供补充信息以便审查和理解检测结果。

我们使用四个大型项目进行实验，共有超过40,000个示例来评估深度学习自动程序（DLAP）。首先，我们进行实验来选择最适合DLAP的DL模型。我们通过将各种DL模型整合到DLAP并比较它们的结果来评估性能，以确定最佳的深度学习模型。结果显示，将Linevul与LLM结合起来在所有评估指标中优于其他DL模型15%。然后我们选择Linevul在DLAP中生成提示，并将DLAP与包括基于角色的提示、辅助信息提示、思维链提示和上下文学习提示在内的最新提示框架进行比较。

结果显示，DLAP在每个项目的所有指标上均超过了基线，实现了比基线高10%的F1分数和20%更高的马修斯相关系数（MCC）。

这表明DLAP在漏洞检测方面更有效。最后，我们将我们的方法与最普遍的微调技术进行比较，以探索DLAP与微调的有效性。结果显示，DLAP能够以更低的成本达到细致微调过程的90%，甚至在某些指标上胜过微调。

此外，DLAP驱动的LLM模型比微调产生更多的解释性文本，这对于帮助开发人员在使用ASAT进行漏洞检测任务方面非常重要。详细的数据和材料请访问：https://github.com/Yang-Yanjing/DLAP.git。

本文的主要贡献如下。

我们提出了DLAP，这是一个定制的LLM提示框架，用于漏洞检测。DLAP结合了DL模型和LLM的优势，并克服了它们各自的缺点。此外，DLAP有潜力被应用于其他ASAT任务。

我们进行了严谨的实验，以展示选择适当的深度学习模型用于深度学习应用程序的有效性，并展示其在检测漏洞方面的卓越性能，明显优于最先进的提示框架。

我们通过实验证明，在漏洞检测中，及时提示的优势胜过细致调整，表现在检测精度、成本效益和解释方面。

本文的其余部分组织如下。第2部分回顾了背景和相关工作。第3部分描述了DLAP的设计。第4部分介绍了DLAP的实验设计和参数设置，随后在第5部分呈现结果和分析。第6部分讨论了DLAP的生成能力和DL模型的选择。最后，我们在第7部分提出了对有效性的威胁，并在第8部分总结本文。

第二部分：背景和相关工作。这部分描述了有关漏洞检测以及LLM（大型语言模型）的提示工程背景的相关研究。

2.1. 漏洞检测
尽管在这个领域有大量的研究，我们着重研究由深度学习和语言模型增强的漏洞检测。

在近年来，漏洞检测引起了很多关注。Lin等人提出了一个框架，结合了一个项目和12个深度学习模型，用于切片级别的漏洞检测。Zhou等人提出了Devign，该框架使用图形表示作为输入，比直接使用代码令牌的方法表现更好。李等人开发了一系列基于深度学习的方法，包括VulDeePecker、𝜇VulDeePecker和SySeVR，用于构建一个应用于漏洞检测的深度学习框架。尽管在实验设置中取得了先进的结果，但在实际应用中仍存在泛化问题。随着基于Transformer架构和语言模型的网络的出现，研究人员已开始将这些先进的自然语言处理技术应用到漏洞检测中。傅和Tantithamthavorn应用RoBERTa作为预训练模型，在随后的漏洞检测任务中进行微调，实现了在功能级别和行级别漏洞预测任务中的最佳实验性能。

Chakraborty等人发现，基于深度学习的几种方法在从多个真实世界项目构建的数据集上的表现平均下降了73%，突显了需要进一步研究跨项目漏洞检测的必要性。Steenhoek等人进行了一项实证研究，以展示模型运行之间的变异性，以及深度学习模型输出之间的低一致性，并研究解释模型以指导未来研究。

2.1.2. 用于漏洞检测的大型语言模型

大型语言模型（LLMs）在对话、代码生成和机器翻译方面表现出色，引发了研究人员和实践者将LLMs应用于软件安全的兴趣。Katsadourosetal.（20）突出了LLMs预测软件漏洞的潜力，强调了它们相对于传统静态方法的优势。Thapa等人（38）发现基于transformer的LLMs胜过传统基于DL的模型。Zhang等人（45）通过创新的提示设计提高了ChatGPT在软件漏洞检测中的效果，并利用模型记忆多轮对话。

然而，根据Cheshkov等人的研究，ChatGPT和GPT-3在Java代码漏洞检测方面并没有超越现有工具的表现。同时，刘等人强调ChatGPT无法取代专业的安全工程师进行漏洞分析，这表明封闭源代码的大型语言模型并非问题的终点。这些发现表明语言模型在漏洞检测领域的性能有待提升。大型语言模型在特定应用中产生的潜在误报和幻觉可归因于广泛的无约束训练数据和大量的训练参数。因此，在将语言模型用于特定任务之前，对其进行精细调整至关重要。Lue等人提出了一种名为GRACE的方法，利用CodeT5处理代码结构，结合语义和句法特征进行相似性搜索，并利用上下文学习提示驱使语言模型在复杂的真实数据集上超越所有基准深度学习模型。

正如上文所指出的那样，当前大型语言模型（LLMs）的性能仍然不尽人意，并伴随着高误报率。在本研究中，GRACE[30] 和其他评估提示[45] 将作为基准，便于进行比较和评估。为了在漏洞检测中取得更好的性能，我们选择了Sysver[24]、Devign[49] 和Linevul[13] 作为我们框架的增强组件。

在为大型语言模型提供提示方面的工程技术
随着LLM中参数数量的增加，微调LLM的成本也在上升。像低秩自适应大型语言模型（LoRA）[17]和P-tuning[28]这样的低成本方法已经显著降低了微调成本。然而，对于某些应用来说，成本仍然相当高。例如，微调具有33B参数的LLM需要两个高精度的40G显卡[17]。已报道的一些参数超过了一千亿，这可能会消耗大量的计算资源。研究表明，LLM是基于transformer的模型[3,8,2]。不同的输入可以导致它们体系结构中的注意力层发生变化，因此，构建高质量的提示可以帮助LLM为特定目标任务提供令人满意的答案。相反，不恰当的提示会影响它的注意力，可能会误导LLM产生幻觉[47]。

在促使工程师编写代码时，目前最有效的方法是使用COT[42]和ICL[11]的提示方式。COT提示是将一个目标问题分解为步骤，以促使LLM提供答案的方法。而ICL则通过提供类似问题的参考，促使LLM给出正确答案。

在这篇论文中，DLAP整合了这两种方法，为驱动LLMs进行漏洞检测提供了适当的提示。

3. 提议的框架：DLAP
本部分描述了DLAP的设计，包括两种提示技术。

3.1. 动机

漏洞检测可以被看作是一个二元分类问题。给定一个用  表示的漏洞数据集  = { (𝑥𝑖, 𝑦𝑖) } 𝑁 𝑖=1，其中 𝑦 = 0 或 1，其中 𝑥𝑖 是一个函数的源代码，而 𝑦𝑖 是真实值（0-否，1-是）。检测模型被期望着自动建立它们的映射关系。检测模型的一个主要过程是输入（源代码）的表示。具体来说，源代码可以被表示为语义标记、抽象解析树（ASTs）、数据/控制流图（DFGs/CFGs）或其他格式。传统的深度学习模型只使用单一格式作为输入，可能会遗漏有用信息。大型语言模型（LLMs）具有结合多种表示的能力，使其成为一种更有前景的漏洞检测技术。在利用LLMs进行漏洞检测时，让LLMs理解领域和任务知识是至关重要的，因为LLMs是通过通用语料库进行训练的。可以预料到，直接使用LLMs进行漏洞检测可能会得到不理想的结果。因此，LLMs使用微调或提示工程来解决这一任务。

微调是一种直观的技术，可以让大型语言模型的参数适应下游任务（例如漏洞检测），以达到更好的结果，可以用方程式（1）来描述。

在函数级代码中，我们需要通过公式(1)来尽量减小损失函数𝜉，其中𝑌是实际标签，通过微调LLMs的权重参数𝜃，我们期望预测的概率能够更接近实际标签。然而，微调是非常耗费成本的。例如，LoRA是最高效的LLMs之一，但仅调整130亿参数的LLM就需要大约80G的显卡内存和大量时间。

杨等人：提交给爱思唯尔的预印本 第3页，共15页 深度学习增强的大型语言模型提示框架 图1：提出的DLAP Prompt工程的概述 是一种增强LLMs的新技术。

大型语言模型（LLMs）可以结合各种输入并生成它们的答案；因此，它们可以被提示 [3, 8, 2]。从技术上讲，我们分别使用 Σ𝑇𝑠 和 Σ𝐸𝑜 来描述预训练集和测试集。在使用提示工程（(̇)）进行漏洞检测时，LLMs接受一组 (𝑋) 作为输入，并输出它们的估计概率，在这里，𝑋表示来自 Σ𝐸𝑜 的示例集合。一种具有成本效益的用于漏洞检测的提示模板  可以用方程式(2)来描述。

在刘等人的文章中指出，式（2）能实现与式（1）相同的效果。也就是说，通过灵活的工程设计和精细调整，可以让预测概率接近于实际真相。在接下来的小节中，我们将详细讨论DLAP，该方法利用了工程设计的方式来进行漏洞检测。

3.2 框架概述DLA在LLM内部利用注意机制，将经过有选择性训练的DL模型作为增强功能进行整合。

这种被称为上下文学习（In-Context Learning，ICL）的方法，可以微调LLM，使其更擅长特定项目。此外，DLAP使用思维链（Chain of Thoughts，COT），能够帮助LLM有效地舍弃不正确的生成路径。因此，DLAP增强了LLM在检测任务中的能力，确保其具有强大的性能而不会产生重大成本。ICL可以激发LLM的注意力层，使其适应下游的检测任务，这被定义为[11]的隐式微调。和一般的微调一样，隐式微调也能够驱使LLM适应下游任务并获得更好的性能。

设计良好的提示可以激发大型语言模型在下游检测任务中表现更好。DLAP框架的理念是利用深度学习模型来增强大型语言模型，通过构建适当的提示来刺激LLMs进行隐式微调，使其适应漏洞检测任务。这样一来，可以减少幻觉和数据分布差异引起的性能下降。

如图1所示，DLAP由两个主要部分组成，包括(1) 第一部分：通过DL模型增强上下文学习提示的构建，以及(2) 第二部分：生成定制的COT提示以增强LLMs。在第一部分中，我们利用DL模型为输入代码生成检测概率，并根据相似性选择候选代码。候选代码及其相应相似性的组合形成了用于检测的ICL提示。

在第二部分中，我们将深度学习模型和静态工具的结果结合起来，以键-值对的形式查询预定义模板库中的COT模板。根据每个输入样本的特征，我们完成思维链条，生成用于检测的COT提示。这两部分将分别在第3.3节和第3.4节中介绍。

在第3.5节中，我们展示了一个例子，说明如何通过结合两个提示来生成最终DLAP的提示。

3.3. 根据之前的观点，大型语言模型（LLMs）通过其庞大的权重结构封装了广泛的知识。首先，我们通过训练集选择预训练的深度学习模型。

对于新项目，我们也可以基于现有研究[13, 24, 49]，利用新收集的样本构建深度学习模型。

为了创建适当的上下文，最相似的编解码候选代码是通过使用局部敏感哈希（LSH）在训练集中找到的，LSH是检索增强生成（RAG）技术中一种高效的相似性搜索算法。尽管LSH相似度计算算法只能涉及代码片段的相似度，但考虑到作为一个提示框架，我们不能花太多时间生成提示形式，因此必须有效地对多个代码进行采样，形成一个相似的代码候选集。

根据Dai等人的研究[11]，我们反过来使用了Yang等人提出的双形式。这是一个由他们提出的注意力变换器框架的深度学习增强大型语言模型提示。因此，DLAP激发的针对特定项目的LLMs的注意力层的自适应隐式微调可以表示为方程(3)。详细信息请参阅附录中的第8部分。

我们通过训练数据info，其中包含了项目数据和标签之间的关系，来训练深度学习模型𝒒，如公式(3)所示：(𝒒)=(𝑊init+Δ𝑊𝐼𝐶𝐿(𝑥))𝐪。然后，深度学习模型会为检测对象𝒙生成检测概率Probs𝜉，如公式(4)所示。

ProbICL(Obj_info) = Prob(Obj_info)(x) (4) DL模型输出的概率代表着输入编码的特征。DLAP 使用这些概率来构建ICL提示，以增强LLMs。然后，我们根据方程（5）获得LLM的放松注意力表示层。

方程（5）表明LLM的放松注意力与DL模型选择输出的概率相关联，并且这些概率与训练项目数据相关。这导致LLM进行隐式微调，以适应特定项目信息。我们在结果分析部分通过比较分析实验进一步详细解释了这一自适应过程。

与传统的微调方法相比，DLAP 不需要大量的资源消耗来更新LLMs 的参数。ICL提示更新LLMs 中注意力层的输出。正如图2中所示的例子，DLAP 的 ICL 提示促使LLMs 进行隐式微调，以适应需要检测的项目的特征。

通过将深度学习模型生成的结果添加到LLM提示中，DLAP能够包含更多相关背景信息。深度学习模型训练生成网络权重，包含了预测概率和输入代码文本之间的复杂关系。因此，深度学习模型的输出具有训练集的特征。

这种方式内置的 ICL 包含比普通 ICL 更多的提示信息，可以激励学习模型在后续任务中表现更好。

如图1上部所示，在通过深度学习模型对候选代码进行检测概率后，我们将代码候选集和相应的概率设置为问题和答案的组合。这些组合（如图2中的示例）被构建为与第3.4节第II部分的上下文学习（ICL）提示一起形成最终的DLAP增强提示。

图 2：DLAP 3.4版本中ICL提示的示例。连贯思维提示生成。DLAP的第二部分是为每个测试样本生成特定的提示。 它分为以下几个阶段。

首先，由于漏洞的特征和检测步骤各不相同，我们需要预先将不同的检测模板存储在一个COT库中。根据现有的同行评议的漏洞分类体系（即，[43, 23]）和可靠的灰色文献（即，[41]），我们构建了一个具有六个主要类别的分层检测COT库。

• 安全功能错误（SFE）：由不完善的安全功能引起的错误
• 物流错误（LOG）：由程序执行引起的错误
• 内存错误（MEM）：与内存资源相关的错误
• 数值错误（NUM）：由数值计算引起的错误
• 不当数据中和错误（IDN）：由于交换数据的非标准化（验证、限制）而引起的错误
• 未知分类错误（UNT）：未知错误

根据CWE研究概念中描述的父子关系，以上一些类别被细分为45个子类别。此外，通过参考与由COT驱动的LLM逐步解决弱点检测的相关研究[29, 45, 32]，我们建立了一个通用的COT生成范式如下。

• 语义学：理解代码的功能。

• 逻辑：分析代码的结构。

•内部风险：识别可能引入漏洞的组件。

在这篇提交给爱思维尔的预印本中，Yang等人提出了一个深度学习增强的大型语言模型提示框架，其中包括外部风险的检查：审查可能导致漏洞的不安全函数。

• 生成 COT：整合上述获取的信息，逐步生成一个COT，用于探究是否存在潜在的漏洞。

具体的COT根据不同类别优化了相应的生成范式。每个子类别都关联着一个特定的检测COT模板指南。DLAP选择了两个开源的功能级漏洞检测静态工具，即Flawfinder和Cppcheck，用于生成静态扫描结果。它解析静态工具的结果文本，并将其映射到分类树中相应的类别上。然后对每个工具进行评分和记录。取最高分的K个类别并添加到查询关键字中。DLAP基于研究结果[49,13,24]选择相同的DL模型，因为它们具有更好的性能。DLAP将DL模型的检测结果与静态工具的扫描结果结合起来，形成查询关键字。

通过使用这个密钥，DLAP 可以从 COT 库中获取定制的 COT 生成指导模板，用于测试代码。

Thekey是一个字典，其中包含了静态工具输出类和DL模型判断结果，就像下图中的例子一样。例如，如果key是属于IDN类别的空指针依赖关系，那么DLAP将会从如图4所示的分类树中获取到精炼的COT指导。COT指导模板库可以在GitHub上公开获取。

通过之前描述的密钥生成过程，将COT指导和DL模型的结果结合起来，生成最终的COT提示，用于针对特定目标的检测样本。

3.5. 促进协同作用的示例

图5展示了我们算法的一个示例，最终提示以这种格式提供。DLAP 生成提示的过程在算法1中进行描述，该算法接受选择的 DL 模型、目标检测项目的训练/历史数据 ={(𝑥𝑖,𝑦𝑖)}𝑁 𝑖=1、选择的静态工具  和预设的 COT 库  作为输入。

首先，目标检测项目𝑋被抽样以构建训练集𝑇𝑜。如果采集到了开源信息，那么𝑇𝑜（如果直接收集到）就被标记为𝑌。接着，剩余部分的检测项目𝑋被用作测试集𝐸𝑜。训练集𝑇𝑜和标签𝑌被用来最小化损失函数𝜙以进行训练。接下来，关于5https://dwheeler.com/flawfinder 6http://cppcheck.net 7https://github.com/Yang-Yanjing/DLAP.git（COTTree）见图4：DLAP算法的精炼COT提示示例。算法1为检测样本定制的提示。输入包括：模型𝜙；样本集合𝑇={(𝑥𝑖,𝑦𝑖)}𝑁 𝑖=1；参数；超参数。

1: 从样本中选择训练集构建基于深度学习的模型，使用标签标记训练集。
2: 找到最小化损失函数的参数。
3: 遍历误差集合中的所有样本。
4: 使用LSH对样本进行编码。
5: 通过参数找到潜在空间。
6: 使用输入得到LID提取的上下文信息和潜在变量。
7: 基于误差集合的排序结果生成ICL提示。
8: 利用生成器得到的预测和排序结果。
9: 使用预测结果作为关键信息检索COT提示生成指导。
10: 使用GPT模型完成提示生成。
11: 深度学习后处理提示等于ICL提示和COT提示的总和。
12: 确保所有检测样本具有特定的COT提示。

在测试集中的每个输入代码中，LSH算法被用来找到这个集合中最相似的代码。然后，DL模型被用来获取检测概率。利用这些候选代码和检测概率，DLAP构建问答组合，形成增强DL的ICL提示。

DLAP按照图5中描述的定制流程获取特定的COT提示。 静态工具被使用以获取分析结果 𝜽(𝐸 𝑜) = {𝜽1：分数，𝜽2：分数，𝜽3：分数，...}，并通过对 𝜽(𝐸 𝑜) 进行排名，获得结果 𝑅𝑒𝑠𝑢𝑙𝑡𝜽(𝑥𝑖)。 然后DLAP生成DL模型预测结果。接着，将结果 𝑃𝑟𝑒𝑑𝑖𝑐𝑡𝑖𝑜𝑛𝑠 组合起来。杨等人：提交给Elsevier的预印本第6页15Deep Learning增强大型语言模型提示框架 图5：DLAP优化的COT提示示例，以形成一个查询，作为检索COT提示生成指南 𝐺(𝑥𝑖) 的关键，从COT库中检索。

GPT被用来完成生成每个检测样本的COT样本(对话聊天样本). 最终，DLAP的最终提示由COT提示和ICL提示组成。每个具体的提示被用来驱动用于检测的LLMs. 最后一步是使用生成的COT提示为LLMs生成可理解的漏洞检测结果，遵循特定的答案格式。

4. 实验设计
这一部分详细介绍了研究问题、数据集、深度学习模型、基准语言模型提示和评估指标。

4.1. 研究问题：DLAP的实验评估按照三个研究问题（RQs）进行设计。

研究问题1：在深度学习辅助漏洞检测中，哪种类别的深度学习模型是最有效的？动机与设置：深度学习辅助漏洞检测的一个重要驱动因素是深度学习模型，它通过ICL方法将深度学习模型训练存储的信息添加到LLMs的提示过程中。鉴于目前对于在漏洞检测中哪种类别的深度学习模型适合增强LLMs的情况了解甚少，我们提出了研究问题1，来比较三种代表性的深度学习模型：Sysevr、Devign和Linevul。

请参阅第4.3节以获取相关原因。

研究问题2：与现有提示框架相比，DLAP有多有效？动机与设置：之前的研究表明，大型语言模型的表现容易受到提示的影响，不恰当的提示会导致性能不佳。在本文中，我们设计了DLAP作为一个加强提示的框架用于漏洞检测。在研究问题2中，我们将DLAP与四个现有的提示框架进行比较：PRol、PAux、PCot、GRACE（详见第4.4节的原理），以评估其有效性。

问题3: DLAP相对于LoRA微调来说效果如何？动机与设置：先前的研究表明微调对于增强语言模型是有帮助的。在本文中，我们使用提示工程而不是微调来开发DLAP，因为它成本更低。在问题3中，我们将DLAP与一种微调的语言模型（Llama-13B） [40] 进行比较，以查看它是否具有与微调相同的性能。具体来说，我们选择LoRA [17]，这是一种最先进的语言模型微调技术，进行比较。

根据Croft等人的研究，常见的漏洞检测数据集存在标签偏差。为了开发一个合适的实验数据集，我们制定了三个选择项目的标准：(1) 该项目已经被相关工作研究过（以确保外部有效性）；(2) 该项目已经累积了超过3,000个函数（排除不活跃项目）；以及(3) 该项目是可追踪的（排除漏洞信息不正确甚至未知的项目）。因此，我们的实验数据集由四个开源项目组成，包括Chrome、Linux、Android和Qemu。我们选择的这些项目都具有良好的开源质量，并且有高质量的漏洞修复记录以保证可追踪性。

我们在表格1中展示了所选项目的基本信息，我们可以看到每个项目中的真实（漏洞）和假样本的数量是不平衡的。为了减轻数据不平衡对训练深度增强学习模型的影响，我们首先对这四个项目的无漏洞样本进行了随机欠采样。接着，我们将数据集按8:2的比例划分为训练集和测试集。训练集用于构建深度学习模型，而测试集则用于评估DLAP的性能。

4.3. DLAP细化为了回答研究问题1，我们选择了三种深度学习模型用于漏洞检测并对DLAP进行改进。这三种模型每一种代表了特定类型的深度学习模型。它们的理由和超参数设置如下。

杨等人：提交给爱思唯尔的预印本 第7页（共15页）深度学习增强的大型语言模型提示框架表1 数据集的基本信息 项目 #函数 #漏洞 Chrome 77,173 3,939 被Chakraborty等人[4]使用的Linux 46,855 1,961 被Fan等人[12]使用的Android 8,691 1,277 被Fan等人[12]使用的Qemu 3,096 125 被Zhou等人[49]使用的 表2 DL模型的设置 DL模型 超参数选择 SysevrJava版本Java 8 静态工具 Joern 0.3.1 图数据库 Neo4j 数据预处理 Slice 嵌入算法 Word2vec -采样算法 CBOW -采样窗口 5 -最小计数 5 网络架构 BiLSTM -迭代次数 100 -批量大小 32 -优化器 sgd -损失函数 二元交叉熵 DevignJava版本Java 8 静态工具 Joern 2.0.157 数据预处理 图嵌入算法 Word2vec -向量大小 100 -迭代次数 10 -最小计数 1 网络架构 CNN -迭代次数 200 -批量大小 128 -输入通道数 115 -隐藏通道数 200 -层数 6 -优化器 adam -损失函数 二元交叉熵 Linevul数据预处理 Slice 嵌入算法 BPE+Transformer 预训练模型 codeBERT -批量大小 256 -注意力头数 12 -优化器 Adam -损失函数 二元交叉熵 •Sysevr[24]代表使用代码特征的类别，包括句法、语义和向量表示。它通过对语义和句法的静态分析，将代码过滤为切片输入。

Devign[49]代表着一种类别，它将更加结构化的图结构和图神经网络引入到漏洞检测模型中。

Linevul[13]代表了利用预训练深度学习模型的分类。这种新颖的系统检测模型基于Transformer架构。

我们选择了这三个深度学习模型，以评估它们所代表的各自类别的一系列相似模型。在我们的模型选择过程中，我们参考了这些深度学习模型在各自研究论文中报告的参数，这些参数是这些模型取得最佳表现时使用的。我们将这些参数选入表2作为我们框架中预设的超参数。通过这样做，我们的目标是复制这些模型所取得的最佳性能，并确保在我们的评估和比较中保持一致性。

我们将WecompareDLAP与利用LLMs来检测漏洞的四个提示框架[45, 34, 30, 44]进行了比较。

PRol(Role-basedprompts)：根据White等人的研究[44]，为GPT提供明确的角色将极大地减轻其幻觉问题。我们的第一个基准模型是由Zhang等人提出的，将GPT打造成一个漏洞检测系统。

我想让你扮演一个漏洞检测系统的角色。

我的第一个请求是“以下程序有错误吗？” 请回答是或否。[代码] ∙ PAux（辅助信息提示）：根据张等人的观点[45]，为LLM提供关于代码更多语义信息可以改善它在漏洞检测中的性能。因此，在基线2中，我们将数据流作为提示的辅助信息提供。

我希望你能充当一个漏洞检测系统，我会给你原始程序和数据流信息，你需要对它们进行操作。以下程序存在错误吗？【代码】【数据流描述】。

根据韦等人的研究，由于大型语言模型在多轮对话中具有潜在的能力，建立思维链有助于提高大型语言模型的推理能力。因此，在基线3中，我们构建了一个两步思维链，来引导大型语言模型在漏洞检测过程中的推理。第一步：确保大型语言模型能够正确判断代码是否存在漏洞。这一步骤促使大型语言模型准确理解代码的目的。

因此，我们设计了第一步提示来检测代码的意图。 第二步：基于第一步，我们继续提示LLMs来检测输入的漏洞。

思维链提示 第一步：请描述给定代码的意图。

请提供要翻译的内容。

第二步：我希望你能扮演一个漏洞检测系统。上面的程序有bug吗？请回答是或否。GRACE：GRACE是一个漏洞检测提示框架，它增强了LLM在软件漏洞检测方面的能力。它通过将代码中的图结构信息整合进来来实现这一目标。GRACE利用代码T5和ICL技术来使用图信息。

杨等人：提交给爱思维尔的预印本 第8页 共15页 深度学习增强的大型语言模型提示框架 4.5. 评估指标 由于在本文中漏洞检测被构建为一个二分类问题，我们使用精确率（P-vul）、召回率（R-vul）和F1分数（F1）来衡量每个框架的性能。考虑到漏洞是一个次要类别，但却具有严重性，我们还使用FPR作为一个度量标准。FPR关注假阳性，因为在它们上犯错会导致比在假阴性上犯错更为严重的后果。在本文中，次要类别（正样本）是漏洞，它所占比例非常小。

FPR的定义如公式（6）所示。此外，马修斯相关系数（MCC）也被用作一种评估指标。MCC，又称为φ系数，是用来衡量在不平衡数据集上二元分类器表现的指标。相比于FPR，MCC是一种更全面的评估指标。MCC的定义如公式（8）所示。

FPR（虚警率）= 错误检测为漏洞的数量 / 实际非漏洞的总数量（6） MCC（马修斯相关系数）= （正确检测漏洞数量 × 正确检测非漏洞数量 - 错误检测漏洞数量 × 错误检测非漏洞数量） / 根号下（（正确检测漏洞数量 + 错误检测漏洞数量） × （正确检测漏洞数量 + 锓错检测非漏洞数量） × （正确检测非漏洞数量 + 错误检测漏洞数量） × （正确检测非漏洞数量 + 错误检测非漏洞数量））（7）其中，TP表示正确检测的漏洞数量，TN表示正确检测的非漏洞数量，FP表示错误检测的漏洞数量，FN表示错误检测的非漏洞数量。

变异系数（CV）是一种统计测量方法，用于确定数据集中数据点相对于其均值的离散程度。当比较具有不同均值数据集的变异性时，特别有价值。CV是通过以下方程计算的：CV = 𝜎/𝜇，其中𝜎代表标准差，𝜇代表数据集的均值。

一个更高的CV值表示数据分布中更大程度的离散性，相对于平均值来说具有更多的变异性。而敏感度、特异度、真正例率和假阳率的取值范围是从0到1，数值越高表示分类器的性能越好。

MCC得分范围是从-1到+1，数值越高则代表分类器的性能越好。我们使用百分比数值（%）来突出结果之间的差异。

5. 结果和分析 这一部分分析实验结果以回答研究问题。

研究人员在四个大型项目中进行了实验，以探究哪一类深度学习模型最适合DLAP。结果见于表3，显示在大部分数据集和指标上，使用Linevul要优于其他模型。比如，在Chrome数据集中，DLAP与Linevul相比表现出最高的MCC达到了37.6%，超过了Deving的26.1%和Sysevr的14.6%。这一发现同样在Linux数据集中得到了验证，其中的MCC为56.4%，而Devign和Sysevr分别为44.4%和8.8%。此外，Linevul的精度和F1得分在各数据集中均显著高于其他模型，凸显了其在较准确地识别漏洞方面的鲁棒性和较少的误报率，也正是由其在数据集中较低的FPR所证实。总体而言，使用Linevul在综合评估指标F1和MCC上超过Deving的平均值分别为7.2%和10.5%。它也在相同的指标上超过Sysevr的平均值分别为28.4%和34.0%。这证明了Linevul相比其他深度学习模型，当集成到LLMs中时具有更优秀的适应性和泛化能力。这些结果表明了将Linevul集成到DLAP中以便检测漏洞的效果，特别是其出色的F1，暗示了较高可能性检测到真正的漏洞。

MCC是二元分类质量的关键指标，它显示了DLAP与Linevul结合解决极度不平衡数据集的能力。

为了进一步区分哪个深度学习模型更适合作为DLAP(深度学习应用程序)的插件，我们还分析了DL模型的中间输出(检测概率)。表4展示了不同DL模型在几个软件项目中性能的变化。在灰色和加粗显示的Linevul模型中，显示出最高的𝐶𝑉。通过比较和分析概率密度分布图Figure6和最大项目数据集Google中的𝐶𝑉Table4，我们注意到与其他模型相比，Linevul显示出更离散的数据分布。这种独特的离散检测分布特性使得LLM生成隐性地对下游检测任务进行更有效的微调。

研究问题1的总结：在三种深度学习模型中，Linevul表现最佳。此外，Linevul显示出最离散的检测概率，这表明它的预测具有最高的置信度，可以最好地激励低水平智能模型。因此，我们选择Linevul作为DLAP的驱动程序，进行后续实验。

5.2. 研究问题2：与其他提示框架的比较。由于OpenAI API调用会带来高昂的成本，我们采用了GPT-3.5-turbo-0125模型来进行漏洞检测。表5展示了使用基准提示框架和DLAP方法的GPT模型之间的性能比较。每个框架的性能都基于五个指标进行评估：精确度（𝜑vul）、召回率（𝜉vul)、F1得分（F1）、假阳率（FPR）和马修斯相关系数（MCC）。

DLAP在几乎所有的指标和数据集上都表现出色，明显优于其他框架。具体来说，DLAP在精度、召回率、F1值和MCC值方面均取得了最高的成绩，展示了其准确识别漏洞能力的优势。以Chrome数据集为例，DLAP的精度为40.4%，召回率为73.3%，显著超过GRACE等下一个最佳框架。此外，DLAP的卓越表现体现在其F1值上，在Chrome达到52.1%，Android为49.3%，Linux为65.4%，Qemu达到惊人的66.7%，比基准框架更高。在假阳率（FPR）方面，DLAP在各数据集上表现中等。尽管与PRoland和PCot等基准相比，DLAP在Chrome、Android和Linux数据集上的FPR并不是最低的，但在F1和MCC上远远优于它们。因此，DLAP的整体效果超出了基准框架。

在这方面，DLAP的MCC值，用于衡量二元分类的质量，明显高于其他方法，例如在Chrome中为37.6%，在Qemu中为63.9%，进一步验证了其在使用LLMs进行漏洞检测任务中的优越性能。我们的框架在MCC指标方面始终超越顶级基准，根据MCC相关系数的性质，这表明我们的预测更准确地反映了实际分布，并表明DLAP在大数据集的泛化性能方面优于基准。

总的来说，分析显示DLAP不仅在高准确率和召回率方面表现突出，还保持着低误报率，并且在F1分数和MCC值方面取得了出色的综合表现。这表明DLAP在利用LLM的强大力量进行漏洞检测方面具有卓越的效果，优于其他提示框架的能力。

研究问题2的总结：DLAP的整体表现优于其他提示框架，这主要体现在其出色的MCC分数以及在vul、vul和F1指标上更高的数值。

研究问题3：提示 vs. 微调。表6显示，在对大型项目进行微调时，LLM比DLAP具有更高的 𝐹1 值。然而，在数据分布不均衡的小型项目中，DLAP表现更好。特别是，在Qemu项目中LLMs无法进行微调，因为该项目的数据量较小。相比之下，DLAP可以获取小样本的分布特征，因此可以实现更好的性能。此外，对LLM进行微调需要停止模型并重新训练后才能使用，而DLAP在使用过程中无需移除再重新训练。它被用作一个插件来实时访问LLM，以增强LLMs的漏洞检测能力。此外，DLAP与LoRA微调之间的计算成本比较如表7所示。显然，对一个13B的LLM进行微调需要接近40GB的显存和大量时间。相比之下，DLAP可以选择一个小的DL模型，并在不到一小时内训练使其适应目标数据。

方程（5）（见第3.3节）表明，DL模型训练信息会改变LLM的放松注意力。

这导致语言模型进行内部微调以适应特定的检测任务。无论是通过微调（如Yang等人所述：提交给Elsevier的预印本第10页15页中的深度学习增强大型语言模型提示框架表5提示框架比较结果框架Chrome Android Linux Qemu vulvul𝐹1 FPR MCC vulvul𝐹1 FPR MCC vulvul𝐹1 FPR MCC vulvul𝐹1 FPR MCC PRol 24.4 07.2 11.1 05.8 02.3 22.5 06.4 10.0 05.6 01.3 22.4 06.6 10.2 05.6 01.7 22.2 06.9 10.5 04.4 04.2 PAux 22.7 54.6 32.1 48.6 04.8 21.8 63.4 32.5 58.3 04.2 24.6 70.2 36.5 52.6 14.1 19.3 55.2 28.6 42.1 09.5 PCot 16.8 05.4 08.1 07.0 02.6 31.6 03.1 05.7 01.7 04.0 30.7 08.0 12.7 04.4 06.5 64.7 38.0 47.8 03.8 43.0 GRACE 32.6 37.5 32.6 80.2 11.2 25.0 82.6 38.4 74.0 08.5 25.0 76.0 37.6 76.0 02.0 17.1 93.1 28.9 82.4 10.6 DLAP 40.4 73.3 52.1 28.4 37.6 34.6 86.2 49.3 41.4 36.1 57.1 76.4 65.4 13.9 56.4 84.2 55.1 66.7 01.9 63.9 表6与微调一起性能比较结果数据集微调Vicuna-13B DLAP vulvul𝐹1 FPR MCC vulvul𝐹1 FPR MCC Chrome 91.4 74.4 82.0 01.8 78.6 40.4 73.3 52.1 28.4 37.6 Android 67.0 35.8 46.7 04.5 40.4 34.6 86.2 49.3 41.4 36.0 Linux 96.4 55.4 70.3 00.5 68.9 57.1 76.4 65.4 14.0 56.4 Qemu 99.9 06.7 12.1 00.1 23.4 84.2 55.2 66.7 01.9 63.9 总计 88.7 43.0 52.8 01.2 52.8 54.1 72.8 58.4 21.4 48.5 表7计算成本比较结果数据集微调DLAP M（MB）T（小时）GPU（GB）M（MB）T（小时）GPU（GB）Chrome 5.1 11.1 31.2 3.6 0.8 6.3 Android 4.9 4.2 30.3 4.3 0.5 5.5 Linux 4.9 5.5 30.3 3.8 0.4 5.5 Qemu 4.8 1.3 28.7 0.9 0.3 2.8 ）或上下文学习（ICL），模型进行微调的程度反映了其适应目标任务的能力，是激励大型语言模型表现良好的关键因素。

根据表6中显示的检测结果，DLAP在评估性能指标的微调逼近方面表现良好。

为了进一步解释是什么机制引起LLM产生隐式微调，并在目标任务上取得良好的性能，我们从经过微调的本地LLM中提取注意力层，以计算每个检测类别的概率。随后，我们通过LLM与DLAP收集ICL输出，以计算每个检测类别的概率。不同类别的概率分布表明模型的微调程度。第5.3节显示微调和DLAP之间的概率分布是相似的。相同的分布说明DLAP能够以较低的成本实现隐式微调。

与微调相比，图8展示了使用DLAP在Linux中检测漏洞的一个真实示例。

DLAP的结果比仅进行微调得到的结果更易于开发者理解。DLAP的结果与实际问题修复记录非常匹配，并且开发者可以轻松理解。相比之下，通过对LLM进行精细调整得到的输出仅限于简单的“是”或“否”回答。

图7：DLAP和微调产生的预测分布总结为RQ3：尽管DLAP的整体表现略低于微调，但它们的预测分布却相似。这个结果表明，DLAP促使语言模型产生了有效的隐式微调，性能与明确微调相当，但成本显著更低。

讨论 在这一部分，我们将讨论关于深度学习应用程序（DLAP）的DL模型选择，以及DLAP的潜在泛化能力。

基于从RQ1中获得的见解，具有离散预测概率密度分布的深度学习模型更适合作为DLAP的集成插件。

此外，我们观察到一个深度学习模型作为LLM提示模型的有效性。我们发现，当它展现出具有最高CV值的离散数据时，其效用显著提高。此外，我们的实验凸显了基于Transformer模型在推动LLM方面的出色表现。这种优势可以归因于Transformer模型与LLM设计架构之间的结构相似性。它们结构上的相似性使得它们能够无缝集成，使来自Transformer模型的注意力层参数在LLM内部发挥重要作用，促进了对LLM的内在微调。

通过利用这些注意层的参数，大型语言模型(LLM)动态调整和精细化其内部机制，隐式地适应不同下游任务的微妙和复杂之处。这种隐式微调过程赋予了LLM生成更准确和与语境相关的回应的能力，从而提升了其在各种应用场景中的整体性能。

总的来说，我们的实验证明了DL模型多样化的符合度以及Transformer模型与LLM架构的相似性所起到的关键作用。这些因素结合了注意力层参数实现的隐式微调，使LLM在适应和满足各种下游任务要求方面表现优异。

6.2. DLAP的泛化能力 DLAP框架有效地激发了LLMs自动对其他软件开发任务进行隐式调优。通过整合现有的静态工具和深度学习模型，DLAP可以应用到各种ASAT任务中。

这种改进简化了采用DLAP来应对新挑战的过程。我们介绍了两种情景，可能扩大了DLAP的适用范围。

自动识别受影响的库是一个ASAT任务，需要找出在公开的漏洞报告集（例如NVD，CVE）中与每个报告漏洞相关的软件中的库。该任务被构建成一个极端的多标签学习[15, 6]。首先，DLAP构建一个足够的漏洞描述数据库，并将其与已知受报告漏洞影响的库结合起来作为用于识别受影响库的COT模板库。已知受影响的库被收集起来训练一个DL模型。然后，利用现有的静态工具（fastXML8）和DL模型为项目中的XML库列表生成参数结果。最后，通过将结果合并为一个键来查询COT模板库，可以建立COT提示以增强LLM，并且从漏洞数据中识别库可能会更加准确。

代码异味检测是一个静态代码分析任务，旨在防止软件中出现技术债务。基于深度学习模型的代码异味检测是一个多分类检测任务，由几个二元分类模型组成，每个模型旨在检测特定类别的代码异味。使用深度学习辅助编程（DLAP）需要创建一个包含代码异味的全面参考库和高质量的编码规范库。然后，DLAP利用静态工具（例如checkstyle）和深度学习模型进行特定检测项目。正如本文所提到的进展，使用深度学习模型增强了低到中等强度异味信息的提示，用以检测项目代码中的具体异味。DLAP也被应用于其他需要将深度学习模型与低级语言模型（LLMs）结合以提升LLMs在目标任务中性能的ASAT任务。

7. 效度的威胁
在这一部分，我们分析了可能存在的对效度的威胁，并说明了我们如何努力减轻它们的影响。

内部有效性。DLA的有效性依赖于其核心组件DL模型。虽然这些DL模型可能会导致对输入代码的判断偏见，但一个完全错误的DL模型，无论是无关紧要的还是对任务有害的，都会严重削弱DLA的性能。因此，在使用DLA时，选择能够有效地增强LLM性能的DL模型至关重要。此外，由于某些LLMs（如GPT-3.5-turbo）的封闭源特性，它们的内部结构和采用的特定微调方法仍然未知。因此，在我们的实验中，我们使用了一个开源LLM（Llama-13b）进行比较微调研究。

构造效度。DLAP的刺激会根据方程（5）改变LLMs的放松注意力。我们定义这种刺激为DLAP引起的LLMs的隐式微调，以适应目标项目的特征。由于观察LLMs内部输出的限制，我们无法严格证明这种刺激对目标分类任务产生梯度下降优化损失。我们并没有通过数学演示，而是展示了一些优势结果和一些对比的中间输出，展示微调，验证了这种隐式微调机制的存在方式实验数据。这些可视化的实验结果在一定程度上消除了本文的构建效度。

外部效度。在验证DLAP时，我们的模板最终需要驱动LLM完成漏洞检测，而完成这一任务的表现被用作评估我们方法有效性的指标。因此，当LLM与实验中选择的LLM不同时，使用DLAP的结果也会不同。我们将LLM的选择视为对此工作的外部效度威胁。在考虑成本和模型性能的同时，我们选择了当前最先进的LLM中成本最低的模型，GPT-3.5-turbo-0125。通过使用最佳模型，我们最大程度地发挥了DLAP的作用。我们提供了具体的模型选择，确保其他工作在使用DLAP时也能获得相同水平的改进效果。

结论：本文中，我们提出了DLAP，这是一个专门用于ASAT任务的提示框架，在软件漏洞检测任务中表现出卓越且稳定的性能，其结果容易让开发人员理解。实验证明了通过DL模型对LLMs进行增强来刺激自适应的隐式微调的有效性。这一进展促使LLMs在漏洞检测中超越了现有的DL解决方案以及具有其他提示框架的LLMs。通过实验，我们还发现LLMs的预训练知识结合了DLAP所有部分的输出来实现良好的性能。未来，我们将在更多ASAT任务中利用DLAP来探索DLAP如何推广到其他任务中。
探究大型语言模型在代码克隆检测中的有效性
摩哈迈德·卡杰扎德 英属哥伦比亚大学基洛纳分校 加拿大 卡杰扎德邮箱地址为 khajezad@mail.ubc.ca
吴杰 地址：英属哥伦比亚大学基洛纳分校 加拿大 吴杰邮箱地址为 jie.jw.wu@ubc.ca
法蒂玛·亨迪亚尼·法德 地址：英属哥伦比亚大学基洛纳分校 加拿大 亨迪亚尼地址为 fatemeh.fard@ubc.ca
格玛·罗德里格斯-佩雷斯 英属哥伦比亚大学基洛纳分校 加拿大 罗德里格斯-佩雷斯地址为 gema.rodriguezperez@ubc.ca
莫哈默德·萨米·谢哈塔 英属哥伦比亚大学基洛纳分校 加拿大 谢哈塔邮箱地址为 mohamed.sami.shehata@ubc.ca

大型语言模型（LLMs）在各种自然语言处理和软件工程任务中表现出色，例如代码生成。LLMs主要应用于基于提示的零/少次训练方式，以指导模型完成任务。基于GPT的模型是研究任务的热门对象之一，如代码注释生成或测试生成。这些任务属于‘生成式’任务。然而，关于LLMs在‘非生成式’任务，比如使用基于提示的分类任务方面的研究有限。在这项初步的探索性研究中，我们调查了LLMs在代码克隆检测（CCD）这一非生成式任务中的适用性。通过从CodeNet派生一个单语和跨语言的CCD数据集，我们首先使用ChatGPT尝试了两个不同的提示，在零次训练设置下检测了Java-Java和Java-Ruby对中的Type-4代码克隆。然后，我们进行了分析，以了解ChatGPT在CCD中的优势和劣势。ChatGPT在跨语言的文本分类任务中超越了基准线，取得了0.877的F1分数。同时，在单语文本分类任务中，取得了0.878的F1分数，与完全微调的模型性能相媲美。另外，问题的提示以及难度级别会影响ChatGPT的表现。最后，我们会根据我们的初步分析提供见解和未来方向。关键词：大型语言模型、代码克隆检测、零-shot 学习、少-shot 学习。1. 介绍 代码克隆，即功能上相同的代码片段，可能导致错误的代码在整个项目中传播[1, 2]。代码克隆检测（CCD）对于开发和维护源代码是必要的，对于各种应用都是有益的，包括寻找库候选项、代码理解、寻找有害软件以及检测抄袭。代码克隆根据相似性度量可分为四种类型：1) 类型-1克隆：在代码和结构上完全相同，仅在空格、注释和布局上有变化的代码片段。2) 类型-2克隆：在语法上完全相同，仅在标识符、文字、类型、空格、布局和注释上有变化的代码片段。3) 类型-3克隆：大部分相似，但在语句方面可能存在差异，同时在标识符、文字、类型、空格、布局和注释上也有变化。4) 类型-4克隆：在语法和结构上完全不同，但功能相同的代码片段。其中，类型-4克隆是最具挑战性的，因为在实现上有不同的语法变体，因此需要较高的推理能力。

我们的代码和数据已经在https://github.com/mkhfring/largeLanguageModels 进行了开源。对于代码重复检测（CCD），提出了不同类型的方法，包括基于文本、基于词汇、基于句法和基于语义的方法。近年来，深度学习方法已经成为软件工程各种任务（如代码克隆检测）的主要方法之一。基于深度学习的代码克隆检测利用深度模型学习克隆之间固有的相似性。这些代码克隆检测器可以有效地检测不同类型的克隆，如Type-3和Type-4。然而，这些方法在处理未见过的问题和超出分布范围的数据时表现不佳。此外，这些模型对跨语言代码克隆检测也不太有效，即对在不同语言中实现的代码片段不太适用。最近，大型语言模型(LLM)因其突出的性能而备受关注。LLM是使用大量参数进行训练的模型（例如，GPT-3有1750亿个参数），采用无监督方式进行训练，在多个领域，包括自然语言处理、机器学习和软件开发等领域都产生了深远影响。这些模型可以分析大量的文本数据，可以进行准确的预测并以零样本方式生成不同的内容，即无需使用任何标记数据[6]。然而，LLM能为CCD问题，特别是Type-4问题提供哪些价值仍不清楚。为了解决这个问题，本文的目标是研究和理解使用LLM进行CCD时的性能和局限性。我们选择Type-4克隆，因为检测这种类型的代码克隆是具有挑战性的。先前的模型发现很难解决Type-4代码克隆，尤其是在少样本学习和跨语言克隆检测的情境下[3]。我们相信大型语言模型的推理能力为Type-4克隆提供了一种有前景的方法。本论文通过利用ChatGPT来检测Java-Java和Java-Ruby代码对中的代码克隆，首先使用两个不同的提示在零-shot环境下进行研究，构建了一个源自CodeNet的单语和跨语言的CCD数据集。此外，我们进行了一项分析，以了解ChatGPT在CCD中的优势和劣势。我们的主要发现是，ChatGPT在跨语言CCD中超越了基线，并实现了与完全微调模型在单语CCD中性能可比的表现。ChatGPT在跨语言CCD中的F1性能为0.877，而CodeBERT等基线实现了0.663的F1分数。此外，提示和问题的难度水平对ChatGPT的性能有影响。2024年1月30日接受arXiv:2401.13802v3 [cs.SE]，已被接受参加2024年4月在葡萄牙里斯本举办的ICPC会议。作者为Mohamad Khajezade、Jie JW Wu、Fatemeh Hendijani Fard、Gema Rodríguez-Pérez和Mohamed Sami Shehata。与现有研究的区别：尽管存在许多关于使用LLMs进行各种与代码相关和软件工程任务的研究[10-12]，但关于LLMs用于代码克隆的研究数量有限。唯一相关的研究是[13,14]。前者探讨了在跨语言生成语义克隆中应用GPT-3的方法，而不是检测克隆。后者评估了不同LLMs在单语设置下进行CCD时的表现。我们的研究与这些工作不同，因为我们专注于单语和跨语言的CCD。此外，我们是首个研究利用LLMs调查CCD问题的复杂性和难易程度的团队。我们进行了两项研究。第一项研究关注的是通过两个研究问题来探讨LLM在代码克隆检测（CCD）中的有效性：问题1：不同提示对鼓励Chat-GPT识别代码克隆的影响是什么？我们在这里研究了我们设计的提示对ChatGPT在Type-4 CCD中的表现的影响，包括单语言和跨语言的情况。我们的目标是探究新提示能在多大程度上提升性能。问题二：与基准模型相比，ChatGPT 在代码克隆检测方面的表现如何？在这个问题中，我们将比较ChatGPT与基准模型的结果，以检测代码克隆。请注意，这个实验中，我们对 ChatGPT 进行了零-shot 设置的测试，而基准模型则是完全微调过的。研究方法

为了回答研究问题1和研究问题2，我们评估了ChatGPT（GPT-3.5-turbo）在零样本二进制代码克隆检测中使用不同提示的性能，评估指标包括F1分数、圈复杂度和接受率。用于指导ChatGPT判断两个代码片段是否为代码克隆的提示 𝑃𝑐 定义如下：𝑃𝑐={𝐶𝑖,𝑗,𝐶𝑘,𝑙,𝑁𝐿}。其中，𝑖和𝑘表示数据集（CodeNet）中的问题编号，而𝑗和𝑙表示问题𝑖和𝑘内的提交编号。如果𝑘=𝑖，则提示中的两个代码片段是代码克隆；否则，它们是非克隆对。设计思路：在我们对提示的调研中，发现直接询问ChatGPT两段代码是否是彼此的克隆是无效的。例如，图1展示了两段实现（code1和code2）的最大公约数（GCD）代码，以及ChatGPT检测这两段代码是否为克隆的能力。尽管ChatGPT能够识别出这两段代码背后的意图，但却无法准确地判断它们是否是克隆代码，这表明它对代码克隆的理解存在误解。因此，询问模型两个给定代码是否是克隆并不会得到正确答案。相比之下，图2展示了ChatGPT的结果。图1中显示的Code1和code2是CodeNET数据集问题#5的两个被接受的提交。图中展示了使用基本提示查询ChatGPT是否代码1和代码2是克隆代码的结果。尽管ChatGPT正确地识别了这两个脚本的功能，但却未能确定它们是否是克隆关系。图2：代码1和代码2是CodeNET数据集[15]问题#5的两个通过的提交，如图1所示。这个图展示了使用我们设计的提示向ChatGPT查询的结果，当它正确指出这两段代码正在解决相同问题时。通过使用本文开发的提示，相同的代码片段被ChatGPT准确地分类为代码克隆。因此，我们的提示旨在要求ChatGPT评估𝐶𝑖,𝑗和𝐶𝑘,𝑙是否打算解决同一个问题。换句话说，ChatGPT应该确定𝑖=𝑘。随后，如果𝑖=𝑘，ChatGPT的任务是确定𝐶𝑖,𝑗和𝐶𝑘,𝑙是否具有相同的输入和输出。在我们的实验中，我们限制ChatGPT输出“是”表示代码重复对，输出“否”表示非重复对。然后，结果被映射为1，表示代码重复，否则为0。最终的提示如下：在2024年4月葡萄牙里斯本的ICPC会议上接受的《对大型语言模型用于代码克隆检测的研究》。“{代码1}，{代码2}”，代码1和代码2是否以相同输入和输出解决相同问题？请用是或否回答，不需要解释。请注意，code1和code2是上述提示中请求的代码。2.2 评估指标 我们在评估中采用了以下三个指标：F1值 F1值，也被称为F-值或F-测量，被用来评估针对二元CCD的模型性能，因为它是用于评估二元分类器准确性的常用性能指标[16]。我们使用平均圈复杂度（CC）来评定每个问题的难度。圈复杂度是一种广泛应用的软件度量标准，用于衡量代码的复杂程度，是根据代码的控制流图来计算的。较高的圈复杂度表示代码更复杂，通常会使其更难以维护、理解和测试。我们计算了CodeNet数据集中每个选定问题的接受率这一指标，以分析每个问题的难度级别，基于其元数据。该指标是使用以下公式进行计算的：接受率𝑝𝑖=𝐶𝑝 𝑖 𝐴𝑝 𝑖，其中𝑝𝑖代表CodeNet数据集中的选定问题，𝐴𝑖表示𝑝𝑖的总提交次数，𝐶𝑖表示𝑝𝑖的正确提交总数。我们使用这一指标的原因是因为它在先前的研究中被用来评估编程问题的难度 [19]，并且能够让先进的深度学习系统根据问题的难度级别对其进行分类 [19]。我们在代码克隆检测研究中使用了Project CodeNet数据集[15]，该数据集包含来自5000多种编程问题的1400万个代码样本，主要涵盖C++、C、Python和Java等50多种编程语言。这些样本包含了被接受和被拒绝的解决方案，以及代码大小和接受状态等元数据。CodeNet的GitHub仓库中的工具可以将这些样本转换为标记序列或解析树。我们对两个数据集进行了抽样：一个用于Java-Java（CCD JJ），另一个用于Java-Ruby（XCCD JR）对，以探索单语言和跨语言代码克隆检测。选择Java是因为它被广泛使用，选择Ruby是因为它在语法上与Java不同且资源较少。每个数据集包括从100个问题中随机选择的1,000个样本（500个正样本，500个负样本对）。正样本对来自同一个问题，而负样本对来自不同问题，确保了选择的平衡性和代表性。我们使用CodeNet的元数据来筛选被接受的解决方案。我们设计的选择方法旨在提供有效的结果比较。我们也选择了CodeNet而不是其他数据集如CodeSearchNet，假设ChatGPT可能对需要预处理的CodeNet不太熟悉，从而可能带来更有洞察力的结果关于模型的能力。值得注意的是，该研究没有使用标准的代码克隆检测数据集有两个原因：首先，对于跨语言代码克隆检测，我们需要包含相同问题的数据集，用不同语言实现。其次，我们需要元数据来计算每个问题的难度。 

表1: 使用ChatGPT进行来自CodeNet的Java-Java对和Java-Ruby对的结果，使用不同温度实验 精确率 召回率 F1分数 Java代码，T=0.3 0.784 0.997 0.878 Java和Ruby代码，T=0.3 0.796 0.977 0.877 Java代码，T=0.1 0.887 0.855 0.852 Java代码，T=0.5 0.889 0.858 0.855 可能导致更有见地的关于模型能力的结果。值得注意的是，该研究没有使用标准的代码克隆检测数据集有两个原因：首先，为了进行跨语言代码克隆检测，我们需要包含用不同语言实现的相同问题的数据集。其次，我们需要元数据来计算每个问题的难度。2.4 基准线对于代码克隆检测，我们将ChatGPT采用的零热身方法与在CodeNET数据集上完全微调的基准线进行比较。这些模型在文献中被广泛使用[5, 20]，包括：CodeBERT: [21] 一种双模预训练模型，用于程序理解和自然语言任务，使用Transformer架构和混合目标函数。它在代码搜索和代码注释生成等任务中表现出色[21]，使其成为合适的基准线。RoBERTa是BERT的一个升级版，专注于掩码语言模型训练，使用更大的学习率、动态掩码和广泛的文本语料库进行训练。它被选中是因为在代码克隆检测方面表现卓越，并且在CodeXGLUE榜单上有出色的成绩。GraphCodeBert是一种变压器模型，它在预训练中强调数据流而不是语法结构，比如AST。它采用了注重结构的方法来增强代码表示，在代码克隆检测、翻译、优化和搜索等任务中表现出色。值得注意的是，我们在进行跨语言检测时，由于数据格式的限制，我们将 C4[5] 从我们的基线中排除了。调查结果如下：表1显示了在Java-Java对中API调用中不同温度下的结果。这些结果是基于先前描述的提议的提示设计。如表所示，当𝑇=0.1，𝑇=0.3和𝑇=0.5时F1-Scores分别为0.852、0.855和0.878。最佳表现出现在𝑇=0.3时。因此，这个温度被用于Java-Ruby对。正如表1所示，Java-Ruby的F1-Score为0.877。研究问题1: 不同提示的影响。表2比较了两个提示，Prompt-1简单地询问ChatGPT两个代码是否是代码克隆，Prompt-2则是本研究提出的提示。如图所示，对于Java-Java对，最低的表现是使用Prompt-1，其F1分数为0.517，精度为1.0，召回率为0.348。有趣的是，Prompt-1对于Java-Ruby对的F1分数为0.834，精度为0.948，召回率为0.745。本研究设计的提示，Prompt-2，对于Java-Java对达到了F1分数0.878，对于Java-Ruby对达到了F1分数0.877。

表3: Java-Java对模型的表现
基准 精度 召回率 F1分数 
CodeBERT 0.912 0.881 0.896 
RoBERTa 0.899 0.852 0.874 
GraphCodeBERT 0.947 0.883 0.914 
ChatGPT 0.784 0.997 0.878 

表4: Java-Ruby对模型的表现
基准 精度 召回率 F1分数 
CodeBERT 0.498 0.988 0.663 
RoBERTa 0.486 0.992 0.652 
GraphCodeBERT 0.50 0.991 0.665 
ChatGPT 0.796 0.977 0.877 

表5: 对于在Java-Java和Java-Ruby数据集中共享的误分类样本，接受率和圈复杂度指标取平均值。正样本代表克隆对的平均值，负样本表示非克隆对的平均值
实验 接受率 圈复杂度 正样本
0.038 2.54
负样本
0.035 3.16
选定问题 0.058 2.98

实验结果表明，Prompt-2在Java-Java对（F1分数为0.878）和Java-Ruby对（F1分数为0.877）上表现均优于Prompt-1。研究问题2：比较表现。由于Prompt-2在我们的第一个实验中取得了最佳分数，我们将在这个研究问题2中将Prompt-2的结果与基准进行比较。对于Java-Ruby对，如在表4中所示，ChatGPT以0.877的F1分数取得了最佳表现。相应地，CodeBERT、RoBERTa和GraphCodeBERT的性能分别为0.663、0.652和0.665。总的来说，在Java-Ruby跨语言数据集中，ChatGPT的表现超越其他基准，实现了0.877的F1分数。相反，其他基准在Java-Ruby对的F1分数范围为0.66左右，精确率和召回率指标表明这些基准主要产生0分。然而，与ChatGPT相比，基准模型对Java-Java对展现出更好的F1分数，得分范围从0.896到0.914，而ChatGPT为0.878。值得注意的是，ChatGPT在这方面表现出色，如图3所示：a)正（蓝色）和负（橙色）错误分类样本的平均接受率比较，以及选定的CodeNet问题（绿色）。较低的接受率表示更复杂的问题。b)正（蓝色）错误分类样本和负（橙色）错误标记样本的平均圈复杂度比较，以及来自CodeNet（绿色）的选定程序。CC越高代表问题越困难。以零-shot 方式表现，而基准模型则完全针对下游任务进行了微调。4讨论 从表1中呈现的结果来看，最佳表现在温度为0.3时达到。然而，正如所示，改变温度并没有显著影响表现。在表格1中另一个值得注意的观察是，Java-Java代码对的性能几乎与Java-Ruby代码对相同，即使跨语言的克隆检测对其他基准模型构成挑战。这个结果的一个合理解释是，ChatGPT在处理Java-Java和Java-Ruby代码对时遇到了特定问题。从表格3和表格4中我们可以看到，在跨语言设置下，基准模型的性能出现下降。比如，GraphCodeBERT的F1分数从0.914降至0.665。这个结果与最近的一项研究结果一致，表明GraphCodeBERT在跨语言的克隆代码检测中存在脆弱性。尽管跨语言的克隆检测更有挑战性，但ChatGPT的性能优于基准。我们假设这个结果可能源自于预训练以及用于训练语言模型的数据集和任务。需要注意的是，语言模型在代码翻译方面具有很高的性能。在Prompt-2中，我们要求模型先识别问题。因此，它可能在Java-Ruby代码对的克隆检测中利用了一些代码翻译的能力。然而，还需要进一步的研究来确定原因。为进一步检验ChatGPT对问题复杂度的敏感性，我们计算了两个评估问题难度和复杂度的指标，即“接受率”和“圈复杂度”。前者表示特定问题的所有提交中被接受的数量，后者是计算程序复杂度的指标。表5展示了Java-Java和Java-Ruby成对共享的误分类问题的这些指标的平均值。在表5中，正例代表ChatGPT错误标记为非克隆的问题相关克隆对的平均难度指标，而负例则显示了被误分类为非克隆对的平均难度。表的最后一行计算了用于本研究数据集取样的全部选定CodeNET问题的平均值，即测试集减去误分类问题。研究大型语言模型在代码克隆检测中的有效性，已被接受至2024年4月葡萄牙里斯本举办的ICPC会议。表5表明，正例问题的复杂度为2.54，低于CodeNET选定问题的平均复杂度。另一方面，负例样本的平均复杂度为3.16，显著高于平均复杂度。图3通过比较正误分类样本的平均接受率和平均圈复杂度，以及这些指标在测试集中的平均值，提供了这些指标更为清晰的说明。这一结果表明，基于接受率和圈复杂度的指标，问题的复杂程度影响了ChatGPT在代码克隆检测中的表现。我们的假设是，代码对越复杂，ChatGPT在代码克隆检测中的推理就变得更具挑战性。威胁。我们使用了一个高质量的公共数据集，并采用了与数据集创建基准一致的模式，使用了标准评估指标，以减轻内部和构建方面的威胁。虽然方法和方法可能在其他编程语言和模型上没有明显不同，但结果可能不适用于其他语言。5. 结论和未来工作
我们进行了一项初步研究，探讨了将语言模型用于第四类代码克隆检测的可能性。初步结果令人鼓舞，我们发现ChatGPT是有效的，并且其表现与问题难度和提示设计有关。在未来，我们打算尝试使用其他预训练于代码的语言模型，比如Phi-2和Mistral，并深入研究我们发现的原因，以及性能是否与特定编程语言相关。致谢 这项研究得到了加拿大自然科学与工程研究理事会的资助，资助号为RGPIN-2019-05175。